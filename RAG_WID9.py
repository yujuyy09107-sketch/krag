import os
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOpenAI
from langchain.chains.retrieval_qa.base import RetrievalQA
from langchain.text_splitter import RecursiveCharacterTextSplitter

# âœ… Streamlit Cloudìš©: Secretsì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
else:
    st.error("âŒ OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Secretsì— ë“±ë¡í•˜ì„¸ìš”.")
    st.stop()


# ğŸ”¹ Streamlit ìºì‹œ ì‚¬ìš©: VectorStoreë¥¼ ìºì‹œí•˜ì—¬ ë°˜ë³µ ë¡œë”© ë°©ì§€
@st.cache_resource(show_spinner=False)
def load_vectorstore(pdf_path="Manual.pdf"):
    # âœ… 1. PDF ë¡œë” êµì²´: PyPDFLoader â†’ PDFPlumberLoader (ë” ì•ˆì •ì )
    try:
        loader = PDFPlumberLoader(pdf_path)
    except Exception:
        loader = PyPDFLoader(pdf_path)

    documents = loader.load()

    # âœ… 2. ë¬¸ì„œ í˜ì´ì§€ ìˆ˜ í™•ì¸
    st.write(f"ğŸ“„ PDFì—ì„œ ì¶”ì¶œëœ í˜ì´ì§€ ìˆ˜: {len(documents)}")

    # âœ… 3. í…ìŠ¤íŠ¸ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,      # ë” í¬ê²Œ (GPU/CPU ë¶€ë‹´ ì¤„ì´ê¸°)
        chunk_overlap=100
    )
    docs = text_splitter.split_documents(documents)
    st.write(f"ğŸ”¹ ë¶„í• ëœ ì²­í¬ ê°œìˆ˜: {len(docs)}")

    # âœ… 4. Embedding ë° Vectorstore ìƒì„±
    embeddings = OpenAIEmbeddings()
    db = FAISS.from_documents(docs, embeddings)
    return db

def main():
    st.set_page_config(page_title="ì„¤ê³„ê´€ë¦¬ìë£Œ RAG ì±—ë´‡", page_icon="ğŸ’¡")
    st.title("ğŸ“ ì„¤ê³„ê´€ë¦¬ìë£Œ ê¸°ë°˜ RAG ì±—ë´‡")

    pdf_path = st.text_input("ê´€ë ¨ìë£Œ:", "Manual.pdf")

    if not os.path.isfile(pdf_path):
        st.warning("âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    with st.spinner("VectorStore ë¡œë“œ ì¤‘..."):
        db = load_vectorstore(pdf_path)

    # Retriever ì„¤ì •
    retriever = db.as_retriever(search_kwargs={"k": 5})

    chat_model = ChatOpenAI(
        model_name="gpt-4o-mini",
        temperature=0
    )

    qa_chain = RetrievalQA.from_chain_type(
        llm=chat_model,
        retriever=retriever,
        chain_type="stuff",
        return_source_documents=True
    )

    query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
    if query:
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            result = qa_chain(query)
        st.markdown("### ğŸ’¡ ë‹µë³€")
        st.write(result["result"])

        st.markdown("### ğŸ“š ê´€ë ¨ê·¼ê±°")
        for i, doc in enumerate(result["source_documents"], 1):
            st.write(f"--- ì°¸ê³ ë‚´ìš© {i} ---")
            st.write(doc.page_content)

if __name__ == "__main__":

    main()
